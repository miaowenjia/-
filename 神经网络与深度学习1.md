# 神经网络与深度学习1

本文是一个零基础开始学习神经网络与深度学习的文章，从环境配置、代码学习到项目实践的学习笔记。

本系列的参考书目为：
李沐等，动手学深度学习（2023年8月中/英文版）

本期内容为神经网络与深度学习概述、环境配置以及线性分类与感知机。

## 神经网络与深度学习概述

人工智能、机器学习、神经网络、深度学习之间的关系可用下图简要描述。

![](/figure/1.png)

神经网络是受到人脑神经元结构启发而设计的一种模型，用于模拟和解决复杂的模式识别问题。简单来说，神经网络的结构包含输入层、隐藏层和输出层，输入层中的多个输入在隐藏层中做多次线性、非线性的组合，再从输出层中进行输出。

![](/figure/2.png)

神经网络是深度学习的基础，深度学习的关键特征是深度神经网络，这个神经网络有多个层（深度），可用让它们学习复杂的表示和特征。深度学习的提出解决了自动提取特征的难题，解决了特征提取的局限性。

## 环境配置

### python环境配置

本文使用Python代码与PyTorch学习神经网络与深度学习。

初学者配置环境时推荐使用Anaconda来进行环境配置，首先下载并安装Anaconda，打开Anaconda Prompt，检查Anaconda是否安装成功，输入指令：

```shell
conda -V
```

若安装成功且Anaconda已经添加到环境变量中，则会输出已安装的Anaconda版本；若输出的不是已安装的Anaconda版本，或输出“不是内部指令”，则可能是环境变量中的path没有添加Anaconda，可以在网上查询相关解决方案。

安装好Anaconda后，创建一个虚拟环境“pytorch”，推荐使用3.9以上的python版本，本文使用的是3.10，输入指令：

```shell
conda create -n pytorch python=3.10
```

然后在命令框中根据指令输入Y即可。

创建好环境后可在conda命令提示框中输入下面的命令来进入虚拟环境

```shell
conda activate pytorch
```

### pytorch配置

pytorch分为CPU版本与GPU版本，CPU版本只能使用核心处理器，在后续进行图像识别或处理时速度会稍慢；GPU版本可以使用独立显卡对图像进行处理，速度较快。

作者的显卡配置为英伟达RTX 4070独立显卡，因此后续内容都是基于GPU版本进行安装（CPU版本的安装也可以在网上查询，并不影响代码实现，只是处理速度会有差别）。

使用win+R并输入cmd打开命令提示框，输入以下命令查看驱动

```shell
nvidia-smi
```

如果存在驱动则会显示如下驱动信息：

![](/figure/3.png)

若没有显示驱动信息，则可能是驱动未安装，可以到英伟达官网下载驱动。

在浏览器中输入pytorch进入pytorch官网，可以浏览到各个版本的pytorch信息，包括GPU版本的安装指令、CPU版本的安装指令。

![](/figure/4.png)

在显卡驱动信息的右上角显示CUDA Version：12.9，则对应可以安装的pytorch版本的CUDA应该<=12.9，作者在这里选择PyTorch Stable Windows Pip Python CUDA12.6版本。

使用conda命令提示框，输入以下命令进入虚拟环境

```shell
conda activate pytorch
```

注意：官网中使用的命令是pip3 install，作者在下载时如果直接使用该命令则会出现超出时间限制的情况，需要把命令中的pip3 install更改为pip install（不能换源下载，因为可能会下载到不同版本的pytorch，如果下载太慢，可以搜索教程本地安装）。输入命令：

```shell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

GPU版本的pytorch相对于CPU版本占用的空间较大，在安装过程中会出现2.5G左右的下载量，若没有出现，则下载的可能为CPU版本。下载结束后在虚拟环境中的命令框中依次输入以下代码来检测pytorch是否正确安装：

```shell
python
```

```python
import torch
torch.cuda.is_available()
```

如果输出为True，则说明pytorch已经完成安装，且安装的是支持GPU版本的pytorch。

### 编译器配置

在编写代码之前，需要下载Visual Studio Code和PyCharm Community两个编程软件。

#### VS Code

下载好VS Code之后，按Ctrl+Shift+X打开扩展，搜索并安装：Chinese(simplified)、Python、Jupyter、Copilot这四个扩展，然后按Ctrl+Shift+P并输入Configure Display Language，把语言切换为中文并重启VS Code。

下载好扩展包之后，需要将虚拟环境添加到VS Code中。创建一个测试文件夹（随便什么地方，可以在D盘根目录下），并点击VS Code左上角的“文件”——“打开文件夹”并打开该文件夹，再新建一个文件名为python文件，先点击右下角标红处，再选择"pytorch"虚拟环境。

![](/figure/5.png)

输入并运行代码：

```python
import torch
print(torch.cuda.is_available())
```

如果环境无误，则会输出True。

若该方法无法正常导入虚拟环境，则还可以使用另一种方法：

进入conda命令提示框中，依次输入：

```shell
conda activate pytorch
```

```shell
where python
```

则可以找到该虚拟环境在系统中的地址

![](/figure/6.png)

再次回到VS Code中，同样点击右下角，在弹出窗口中选择“输入解释器路径”，按照上方命令输出的虚拟环境地址进入，将python.exe作为解释器即可。再次输入代码检查环境是否正确：

```python
import torch
print(torch.cuda.is_available())
```

### Pycharm Community

下载并安装好pycharm之后，随便创建一个项目来对编译器进行配置。

进入项目中后，使用Ctrl+Alt+S打开设置，在搜索框中搜索Chinese进行汉化，重启pycharm。回到项目中后，再次使用Ctrl+Alt+S打开设置，点击“项目：XXX”——“Python解释器”——“添加解释器”——“添加本地解释器”——“现有”并找到上述地址中的python.exe文件即可。

![](/figure/7.png)

同样输入并运行下述代码来验证环境是否配置无误。

```python
import torch
print(torch.cuda.is_available())
```
## 线性分类与感知机

之前说过神经网络实际就是多个输入端之间进行多次线性与非线性的组合，因此先从“线性问题“入手。

### 线性回归

1. 线性模型是指目标可以表示为特征的加权和，例如：房价可能会受到房屋面积和房屋年龄的影响，可以表示为

$$
price=w_{area} \cdot area+w_{age} \cdot age + b 
$$

​	上式中的area和age都是特征，w_area和w_age成为权重，权重决定了每个特征对预测结果的影响，b是偏置。

2. 线性回归的要素

   训练集或训练数据中的特征——输入数据（一般称为x）；

   输出数据（一般称为y）；

   拟合的函数（或称为假设或模型），一般写作
   
$$
\hat{y}=h(x)
或
\hat{y}=kx+b(\hat{y}表示预测值)
$$
   
   训练的条目数：一条训练数据是由一堆输入数据和输出数据组成的，输入数据的维度为n（特征的维度）。

3. 将式特征数扩展到d维，则可写为

$$
\hat{y}=w_1x_1+w_2x_3+...+w_dx_d+b
$$
   
   也可以写成矩阵形式

$$
\hat{y}=h_\theta(\mathbf{x})=\mathbf {w}^T\mathbf {x}+b
$$
   
   上式中表示了一条训练数据中有d维特征时的预测情况，当训练数据扩展到n条时，则可写为
   
$$
\mathbf{\hat{y}}=\mathbf{h}_{\Theta}(\mathbf{X})=\mathbf {X}\mathbf {w}+b
$$

4. 损失函数

   在有了模型后，还需要一种度量模型质量的方式——损失函数

$$
J(\Theta) = \frac{1}{2n}\sum_{i=1}^n (y^{(i)} - h_\theta (\mathbf{x}^{(i)}))^2
$$
   
   模型训练的目标就是找到一组合适的超平面参数**w**与b，使得损失函数的值最小，即

$$
\min_\Theta J(\Theta)
$$

   在线性回归模型中，可以得到解析解
   
$$
\cfrac{\partial J(\Theta)}{\partial \Theta}=0
$$
$$
\Theta=(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}
$$
   
   但在实际情况中，很少会出现可以求出解析解的情况，往往只能通过数值方法求出数值解。

5. 线性分类问题

   线性分类器可以借助特征之间的线性组合来做出分类决定，即找到一条或几条直线（或超平面）来将对象进行分类。

   输入：特征向量；

   输出：哪一类（如果是二分类问题则输出0和1，或是属于某类的概率——0~1之间的数）

   ![](figure\8.png)

   思路：构造一条直线（超平面），将各点的特征带入直线（超平面）中时，就可以通过值的正负来判断其位于直线（超平面）的上方或下方。但我们最终需要概率，结果需要位于0~1之间，因此需要对值进行一个变换：
   
$$
\theta_1x_1+\theta_2x_2+\theta_0=0
$$

$$
z=\theta_1x_1+\theta_2x_2+\theta_0
$$

$$
\hat{y}=h_\theta(\mathbf{x}^{(i)})=\cfrac{1}{1+e^{-z}}
$$
   
   经过变换，可将“点在直线上方（下方）”的问题等价为“输出y位于0.5到1之间（0到0.5之间）”。同样也需要给定一个损失函数
   
$$
J(\Theta)=\cfrac{1}{2n}\sum_{i=1}^n(y^{(i)}-h_\Theta(\mathbf{x}^{(i)}))^2
$$
   
   注意这里的y只能取0/1。
   在这个损失函数中，损失函数变成了非线性，无法直接求出解析解，因此只能使用数值解法。

6. 梯度下降法

   算法步骤如下：

   （1）初始化模型参数，如随机初始化；

   （2）从数据集中随机抽取小批量样本**B**且在负梯度上更新参数。

   用数学表达式描述：

$$
\theta=\theta-\cfrac{\eta}{|\mathbf{B}|}\sum_{i\in\mathbf{B}}\cfrac{\partial(y^{(i)}-h_{\theta}(\mathbf{x}^{(i)}))^2}{\partial \theta}
$$
$$
\mathbf{w}=\mathbf{w}-\cfrac{\eta}{|\mathbf{B}|}\sum_{i\in\mathbf{B}}\cfrac{\partial(y^{(i)}-h_{\theta}(\mathbf{x}^{(i)}))^2}{\partial \mathbf{w}}
$$
$$
b=b-\cfrac{\eta}{|\mathbf{B}|}\sum_{i\in\mathbf{B}}\cfrac{\partial(y^{(i)}-h_{\theta}(\mathbf{x}^{(i)}))^2}{\partial b}
$$
   
   其中，学习率和样本数通常都是预先手动设定，仅需要迭代求出**w**和b即可。

   但梯度下降法也有局限性：

   批量下降法能够找到全局最优点，但收敛速度太慢，浪费学习时间；

   随机梯度下降法虽然收敛速度快，但容易陷入局部最优；

   小批量下降法每次可以使用一小批样本进行训练，收敛速度块且相比随机梯度下降法而言更容易找到全局最优点，但其对学习率也非常敏感，对不适宜的学习率也会陷入局部最优。

7. 线性回归的代码实现

   在这里选用相对简单的带有噪声的线性模型来构造数据集，任务是使用这个有噪声的有限样本数据集来恢复这个模型的参数。
   
$$
\mathbf{y}=\mathbf{X}\mathbf{w}+b+\varepsilon\\
\mathbf{w}=\begin{bmatrix}
2  &  -3.4
\end{bmatrix},b=4.2
$$

   ```python
   import random
   import torch
   ```

   ```python
   def synthetic_data(w,b,num_examples):
       '''生成y=Xw+b+噪声'''
       X = torch.normal(0, 1, (num_examples, len(w)))
       y = torch.matmul(X,w) + b
       y += torch.normal(0, 0.01, y.shape)
       return X, y.reshape((-1, 1))
   ```

   ```python
   true_w = torch.tensor([2, -3.4])
   true_b = 4.2
   features, labels = synthetic_data(true_w, true_b, 1000)
   ```

   features中的每一行都包含一个二维数据样本，labels中的每一行都包含一维标签值（一个标量）

   ```python
   features, labels # 查看随机取出的一组features和labels
   ```

   需要每次抽取小批量样本来更新模型，所以需要定义一个函数，该函数能打乱数据集中的样本并以小批量的方式来获取数据

   ```python
   def data_iter(batch_size, features, labels):
       num_examples = len(features)
       indices = list(range(num_examples))
       random.shuffle(indices)
       for i in range(0, num_examples, batch_size):
           batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])
           yield features[batch_indices], labels[batch_indices]  
           
   batch_size = 10
   
   for X,y in data_iter(batch_size, features, labels):
       print(X, '\n', y)
       break
   ```

   有了小批量样本，接下来就需要一个初始化的模型来进行训练

   ```python
   w = torch.normal(0, 0.01, size=(2,1), requires_grad=True) # requries_grade代表是否需要通过梯度来训练
   b = torch.zeros(1, requires_grad=True)
   
   def linreg(X, w, b):
       '''线性回归模型'''
       return torch.matmul(X, w) + b
   
   def squared_loss(y_hat, y):
       '''定义均方损失'''
       return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
   
   def sgd(params, lr, batch_size): # lr代表学习率
       '''对params中的参数分别进行小批量随机梯度下降'''
       with torch.no_grad():
           for param in params:
               param -= lr * param.grad / batch_size
               param.grad.zero_()
               
   lr = 0.03
   num_epochs = 3
   net = linreg
   loss = squared_loss
   ```

   有了模型、损失函数和梯度下降方法之后，就要进行参数更新，直到这些参数足以拟合我们的数据

   ```python
   for epoch in range(num_epochs):
       for X, y in data_iter(batch_size, features, labels):
           l = loss(net(X, w, b), y) # X和y的小批量损失
           # 因为l的形状是(batch_size, 1)而不是标量，因此需要将其所有元素加在一起来计算关于[w, b]的梯度
           l.sum().backward() # 求和后进行反向传播
           sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数
       with torch.no_grad():
           train_l = loss(net(features, w, b), labels)
           print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
   ```

   ```
   epoch 1, loss 0.045112
   epoch 2, loss 0.000198
   epoch 3, loss 0.000049
   ```

   再输出估计误差来观察模型拟合程度

   ```python
   print(f'w的估计误差是：{true_w - w.reshape(true_w.shape)}')
   print(f'b的估计误差是：{true_b - b}')
   ```

   ```
   w的估计误差是：tensor([ 0.0005, -0.0007], grad_fn=<SubBackward0>)
   b的估计误差是：tensor([0.0012], grad_fn=<RsubBackward1>)
   ```

8. 线性回归的简洁实现

   我们可以通过调用pytorch框架中现有的API来读取数据，可将features和labels作为API的参数传递，并通过数据迭代器指定batch_size。

   ```python
   from torch.utils import data
   
   # 将data_arrays里面的数据按照批量大小每次（是否随机）选择出来
   def load_array(data_arrays, batch_size, is_train=True):
       '''构造一个pytorch数据迭代器'''
       dataset = data.TensorDataset(*data_arrays)
       return data.DataLoader(dataset, batch_size, shuffle=is_train) # is_train代表是否用于训练（在每轮训练中打乱数据）
   
   ```

   将数据中每批取10个放入数据迭代器中

   ```python
   batch_size = 10
   data_iter = load_array((features, labels), batch_size)
   ```

   每次取出的数据都不一样

   ```python
   next(iter(data_iter))
   ```

   ```
   [tensor([[-0.5667, -0.6789],
            [ 0.2148, -0.0394],
            [-1.0998,  0.3105],
            [ 1.7271,  1.9814],
            [-0.9196, -0.8750],
            [ 1.1136,  0.8771],
            [-0.8499, -2.1416],
            [-0.0124,  2.5012],
            [ 0.6964,  0.6722],
            [ 1.5590,  0.8128]]),
    tensor([[ 5.3773],
            [ 4.7589],
            [ 0.9514],
            [ 0.9300],
            [ 5.3260],
            [ 3.4574],
            [ 9.7711],
            [-4.3158],
            [ 3.3053],
            [ 4.5558]])]
   ```

   定义模型，首先定义一个模型变量net，该模型变量是一个Sequential类的实例，将多个层串联起来。当给定输入数据时，Sequential实例将数据输入到第一层，然后将第一层的输出作为第二层的输入，以此类推。下面代码中，我们只定义了一层网络，且该层网络使用了线性网络nn.Linear，该网络的输入参数中，第一个参数代表特征的维度，第二个参数代表输出的维度，由于features中有两个维度、labels是标量即只有一个维度，因此输入参数(2,1)。

   ```python
   from torch import nn
   # nn是神经网络的缩写
   
   net = nn.Sequential(nn.Linear(2,1))
   ```

   在使用模型net之前，还需要对模型参数初始化，如在线性回归模型中设置权重和偏置（深度学习框架通常有预定义的方法来初始化参数）。在这里我们将每个权重参数从均值为0、标准差为0.01的正态分布中进行随机取样，偏置参数初始化为0。

   ```python
   net[0].weight.data.normal_(0, 0.01)
   net[0].bias.data.fill_(0)
   ```

   然后再定义损失函数，在神经网络中，计算均方误差使用的是MSELoss类，也成为平方L_2范数，默认情况下它将返回所有样本损失的平均值。

   ```python
   loss = nn.MSELoss()
   ```

   需要进行优化的参数为权重和偏置，这两项可以使用net.parameters()来读取，且在pytorch中的optim模块中实现了很多的优化算法，这里我们还是选择使用SGD算法来进行优化。

   ```python
   trainer = torch.optim.SGD(net.parameters(), lr=0.03)
   ```

   有了训练器之后就可以开始进行训练了，通过深度学习框架的高级API来实现仅需要少量的代码，并且使用trainer.step()即可自动进行训练。

   ```python
   num_epochs = 3
   for epoch in range(num_epochs):
       for X, y in data_iter:
           # 定义损失函数
           l = loss(net(X), y)
           #反向传播
           trainer.zero_grad()
           l.backward() 
           #更新参数
           trainer.step()
       l = loss(net(features), labels)
       print(f'epoch {epoch+1}, loss {l:f}')
   ```

   ```
   epoch 1, loss 0.000314
   epoch 2, loss 0.000094
   epoch 3, loss 0.000095
   ```

   所得到的估计参数与生成数据所用到的实际参数非常接近。

   ```python
   w = net[0].weight.data
   print('w的误差:', true_w - w)
   b = net[0].bias.data
   print('b的偏差:', true_b - b)
   ```

   ```
   w的误差: tensor([[0.0004, 0.0001]])
   b的偏差: tensor([-0.0010])
   ```

   
### softmax回归

#### 基本思想

对于一个分类问题，我们希望模型能够返回某一对象属于某种类型的概率，并根据最大概率的类型来确定该对象所属的类型。既然需要输出一个概率，那么就需要满足两个条件：非负、概率之和为1。要如何获得这个概率呢？

我们从一个图像分类开始，假设每次输入的图像都是一个2像素*2像素的灰度图像，那么这些图像每个就都有**四个**特征值。此外，假设这些图片可能有三种类型：“狗”、“猫”、“鸡”。对应的第一种类是狗，第二种类是猫，第三种类是鸡，因此：

$$
x_1:第一特征；x_2:第二特征;x_3:第三特征;x_4:第四特征
$$

$$
y_1:对象属于狗的概率;y_2:对象属于猫的概率;y_3:对象属于鸡的概率
$$

在我们前面的学习中我们使用了线性回归来根据多个特征输出一系列的结果，由于我们有三种类型，因此我们需要返回三个输出，即模型为一个四输入——三输出的单层神经网络。

![](/figure/9.png)

例如第i张照片放入模型中的输出可表示为：

$$
o_1^{(i)}=x_1^{(i)}w_{11}+x_2^{(i)}w_{12}+x_3^{(i)}w_{13}+b_1
$$

$$
o_2^{(i)}=x_1^{(i)}w_{21}+x_2^{(i)}w_{22}+x_3^{(i)}w_{23}+b_2
$$

$$
o_3^{(i)}=x_1^{(i)}w_{31}+x_2^{(i)}w_{32}+x_3^{(i)}w_{33}+b_3
$$

但是这输出的并不是我们想要的，我们想要的是一个概率，现在的输出有正有负，也可能大于1，因此所有的**o**仅为为规范化的预测。

因此需要在这些线性回归模型上进行一个softmax运算：

$$
\hat{y_1^{(i)}}=\frac{\exp(o_1^{(i)})}{\sum_k \exp(o_k^{(k)})}
$$

$$
\hat{y_2^{(i)}}=\frac{\exp(o_2^{(i)})}{\sum_k \exp(o_k^{(k)})}
$$

$$
\hat{y_3^{(i)}}=\frac{\exp(o_3^{(i)})}{\sum_k \exp(o_k^{(k)})}
$$

写成紧密形式：

$$
\hat{\mathbf{y}^{(i)}}=\frac{\exp(\mathbf{o}^{(i)})}{\sum_k \exp(\mathbf{o}^{(k)})}
$$

使用softmax运算之和，就可以得到一个规范的概率型的预测，且不影响未规范前**o**预测的大小顺序。

尽管softmax是一个非线性函数，但规范化的输出**y**只依赖于为规范化的输出**o**，因此softmax回归仍然是一个线性模型。

基本思想有了，还需要对小批量样本进行向量化以及建立一个损失函数。

#### 小批量样本线性化

在整个训练样本集中，选出大小为n的批量样本，其中每个样本的特征维度为d维，假设输出有9个类别。则：

$$
小批量样本特征:\mathbf{X}\in \mathbb{R^{n\times d}},权重为:\mathbf{W}\in \mathbb{R^{d\times q}},偏置为:\mathbf{b}\in \mathbb{R^{1\times q}}
$$

$$
\mathbf{O}=\mathbf{X} \mathbf{W}+\mathbf{b}
$$

$$
\hat{\mathbf{Y}} = solftmax(\mathbf{O})
$$

上面的**XW+b**，虽然**b**和前面的**XW**并不是统一维度，但由于广播机制，最后的输出也是n×q维的。

在**X**中，每一行代表一个数据样本，softmax运算可以按行执行：对于**O**的每一行，先进行求幂运算，再求和，然后进行标准化。

#### 损失函数

接下来我们需要一个损失函数来度量预测结果。使用极大似然估计法。

softmax函数输出了对象属于某一类型的概率，我们可以将其视为：“对给定任意输入x的每个类的条件概率”，说得更容易理解一点：
上面我们说了第一种类为狗，第二种类为猫，第三种类为鸡，预测的y1就是在给定样本为x的条件下，这个样本x确实是猫的概率。即

$$
\hat{y_1}^{(i)}=P(y^{(i)}=猫|x^{(i)})
$$

假设整个数据集{**X**，**Y**}中共有N个样本，其中索引为*i*的样本由特征向量x^i和标签向量y^i组成，因此我们可以将估计值与实际值进行比较：

$$
\hat{\mathbf{Y}}=P(\mathbf{Y}|\mathbf{X})=\prod_{i=1}^NP(\mathbf{y^{(i)}}|\mathbf{x^{(i)}})
$$

根据最大似然估计，我们最大化P(**Y**|**X**)，相当于最小化负对数似然：

$$
-\log P(\mathbf{Y}|\mathbf{X})=\sum_{j=1}^n -\log P(\mathbf{y^{(i)}}|\mathbf{x^{(i)}})=\sum_{j=1}^n l(y^{(i)},\hat{y}^{(i)})
$$

因此我们对于任何标签**y**和模型预测**y_hat**，损失函数为：

$$
l(\mathbf{y},\mathbf{\hat{y}})=-\sum_{j=1}^q y_j\log\hat{y_j}
$$

上面的损失函数通常称为交叉熵损失（cross-entropy loss）。

而对于上面的损失函数，利用softmax函数的定义可以进行化简：

$$
l(\mathbf{y},\mathbf{\hat{y}})=-\sum_{j=1}^q y_j\log \frac{\exp(o_j)}{\sum_{k=1}^q (o_k)0}
$$

$$
=\sum_{j=1}^q y_j \log\sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j
$$

$$
=\log\sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j
$$

从第二个“=”到第三个等号中间的y_j怎么不见了呢？那是因为独热编码的特性。什么是独热编码？以上面所举得狗、猫、鸡为例，假设第i个样本属于狗，即第一类别，那它的独热编码就为

$$
\mathbf{y}^{(i)} = [\begin{matrix} 1 & 0 & 0 \end{matrix}]
$$

也就是说，对于任意一个样本，只要它对应其中一个类别，那么它的独热编码就只会在对应位置为1，其余位置都为0。

因此，使用化简后的损失函数就可以轻松进行求导：

$$
l(\mathbf{y},\mathbf{\hat{y}})=\log\sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j
$$

$$
\frac{\partial l(\mathbf{y},\mathbf{\hat{y}})}{\partial o_j}=\frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \hat{y_j} - y_j = softmax(\mathbf{o})_j-y_j
$$

$$
\frac{\partial l(\mathbf{y},\mathbf{\hat{y}})}{\partial \mathbf{O}}=\mathbf{\hat{y}}-\mathbf{y}
$$

但要使用梯度下降法，需要知道的是损失函数对权重的偏导和损失函数对偏置的偏导，因此还需要使用链式法则。

$$
\mathbf{O}=\mathbf{X} \mathbf{W}+\mathbf{b}
$$

$$
\frac{\partial \mathbf{O}}{\partial \mathbf{W}}=\ \mathbf{X}^\top \quad \Rightarrow \quad \frac{\partial l}{\partial \mathbf{W}} = (\hat{\mathbf{y}} - \mathbf{y}) \cdot \mathbf{X}^\top
$$

$$
\frac{\partial \mathbf{O}}{\partial \mathbf{b}} = \mathbf{I}_{q\times q} \quad \Rightarrow \quad \frac{\partial l}{\partial \mathbf{b}} = \hat{\mathbf{y}} - \mathbf{y}
$$

使用梯度下降来对参数进行优化：

$$
\mathbf{W} = \mathbf{W} - \eta \frac{\partial l}{\partial \mathbf{W}}
$$

$$
\mathbf{b} = \mathbf{b} - \eta \frac{\partial l}{\partial \mathbf{b}}
$$

#### 图像分类数据集

这里使用的是Fashion-MNIST数据集。利用框架中的内置函数将Fashion-MNIST数据集下载并读取在内存中：

```python
import torch
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l

d2l.use_svg_display()
```

```python
# 将FashionMNIST数据集下载下来并读取到内存中
# 为了训练，将图片的像素点除以255，使得每个像素点的像素值处在0~1之间
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True)
```

FashionMNIST数据集中共有10类数据，每一类数据都有6000个训练集和1000个验证集，因此共有60000个训练集和10000个验证集。

```python
len(mnist_train), len(mnist_test)
```

```
(60000, 10000)
```

每个输入图像的高度和宽度都为28像素，数据集由灰度图像组成，其通道数为1，在这里我们将高度为h和宽度为w的像素图像形状记作h*w，即h行、w列，或(h,w)。

```python
mnist_train[0][0].shape # 查看训练数据集中的第一个训练数据形状
```

```
torch.Size([1, 28, 28])
```

数据中包含的10个类别分别为：T恤、裤子、套衫、连衣裙、外套、凉鞋、衬衫、运动鞋、包和短靴，以下函数用于在数字索引及其文本名称之间进行转换。

```python
def get_fashion_mnist_labels(labels):
    '''返回Fashion-MNIST数据集的文本标签'''
    text_labels = ['T恤','裤子','套衫','连衣裙','外套','凉鞋','衬衫','运动鞋','包','短靴']
    return [text_labels[int(i)] for i in labels]
```

再创建一个函数来可视化这些样本

```python
def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
    """绘制图像列表"""
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    d2l.plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            # 图片张量
            ax.imshow(img.numpy())
        else:
            # PIL图片
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes
```

下面是训练数据集中前几个样本的图像及其相应的标签：

```python
X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y))
```

```
array([<Axes: title={'center': '短靴'}>, <Axes: title={'center': 'T恤'}>,
       <Axes: title={'center': 'T恤'}>, <Axes: title={'center': '连衣裙'}>,
       <Axes: title={'center': 'T恤'}>, <Axes: title={'center': '套衫'}>,
       <Axes: title={'center': '运动鞋'}>, <Axes: title={'center': '套衫'}>,
       <Axes: title={'center': '凉鞋'}>, <Axes: title={'center': '凉鞋'}>,
       <Axes: title={'center': 'T恤'}>, <Axes: title={'center': '短靴'}>,
       <Axes: title={'center': '凉鞋'}>, <Axes: title={'center': '凉鞋'}>,
       <Axes: title={'center': '运动鞋'}>, <Axes: title={'center': '短靴'}>,
       <Axes: title={'center': '裤子'}>, <Axes: title={'center': 'T恤'}>],
      dtype=object)
```

![](\figure\10.png)

将数据的标签从数字变为文本之和，就可以使用小批量的方法来读取数据来训练，下面定义一个小批量数据读取函数

```python
batch_size = 256

def get_dataloader_workers():  #@save
    """使用4个进程来读取数据"""
    return 4

train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,num_workers=get_dataloader_workers())
```

再来看一下读取训练数据所需要的时间

```python
timer = d2l.Timer()
for X, y in train_iter:
    continue
f'{timer.stop():.2f} sec'
```

然后定义一个数据集读取的函数，用于返回训练集和验证集的数据迭代器，此外，这个函数还接收一个可选参数resize，用来将图像大小调整为另一种形状。

```python
def load_data_fashion_mnist(batch_size, resize=None):  #@save
    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))
```

#### 从零实现softmax回归

```python
import torch
from IPython import display
from d2l import torch as d2l
```

```python
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

原始数据集中的每个图像都是28×28一共是784个像素的图像，在进行训练是，我们将其平展开，即把28×28的图像变为长度为784的向量。虽然在一个图像中，可以根据其图像空间的结构特征来选取特征，但在这里我们将使用每一个像素作为一个特征。所以输入的特征为784维，且有10个种类，因此，我们需要将权重矩阵设置为784×10，偏置设置为1×10的行向量。与线性回归一样，使用正态分布来初始化权重W，将偏置初始化为0。

```python
num_inputs = 784
num_outputs = 10
W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)
```

在pytorch中，可以使用sum运算符来沿着张量的特定维度求和。

```python
def softmax(X):
    X_exp = torch.exp(X)
    partition = X_exp.sum(1, keepdim=True) # 按照第二个维度（列）来进行求和，并且要保持他们的维度
    return X_exp / partition
```

使用softmax函数，不论使用什么X，最终生成出来的都满足概率的要求：非负、总和为1。用下面的正态分布下的X来验证。

```python
X = torch.normal(0, 1, (2, 5))
X_prob = softmax(X)
X_prob, X_prob.sum(1)
```

```
(tensor([[0.0332, 0.0076, 0.7700, 0.0623, 0.1268],
         [0.1419, 0.0955, 0.2627, 0.4339, 0.0660]]),
 tensor([1.0000, 1.0000]))
```

定义模型

```python
def net(X):
    '''-1代表会自动推断样本大小，torch.matmul()这个方法是矩阵乘法'''
    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) 
```

定义损失函数

```python
y = torch.tensor([0, 2]) # 真实值，第一个样本属于类别0，第二个样本属于类别2
y_hat = torch.tensor([[0.1, 0.3, 0.6],  # 第一个样本的测量值为：属于类别0的概率为0.1，属于类别1的概率为0.3，属于类别0.6的概率为0.6
                      [0.3, 0.2, 0.5]]) # 第而个样本的测量值为：属于类别0的概率为0.3，属于类别1的概率为0.2，属于类别0.6的概率为0.5
y_hat[[0, 1], y] # 这是pytorch的高级索引，相当于[y_hat[0, y[0]],y_hat[1, y[1]]]，即y_hat[0]属于y[0]类别(类别0)的概率、y_hat[1]属于y[1]类别(类别2)的概率
```

```
tensor([0.1000, 0.5000])
```

再定义一个交叉熵损失

```python
def cross_entropy(y_hat, y):
    '''定义了一个交叉熵损失'''
    return - torch.log(y_hat[range(len(y_hat)), y])

cross_entropy(y_hat, y) # 计算y_hat与y的交叉熵损失
```

```
tensor([2.3026, 0.6931])
```

既然是分类问题，那就一定会将一个样本确定地分到某个类中，即使该样本对于位于每个类别都有概率，那我们也应该取概率最高的一个类别作为其最终分类。此时就需要计算它的分类精度。如果y_hat是矩阵，那么假定第二个维度存放着每个类别的预测概率，我们使用argmax来获得每行中最大元素的索引来获得预测类别，然后将预测类别y_hat与真实类别y进行比较。这时我们就可以统计预测正确的数量。

```python
def accuracy(y_hat, y):
    '''计算预测正确的数量'''
    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype) == y
    return float(cmp.type(y.dtype).sum())
```

由于上面定义的y和y_hat，第一个样本预测属于类别2，但其真实类别属于类别0；第二个样本属于类别2，真实类别属于类别2。因此预测准确率是0.5

```python
accuracy(y_hat, y) / len(y)
```

```
0.5
```

同样，对于数据迭代器data_iter可以访问的数据集，我们可以评估其在任意模型net上的精度。

```python
def evaluate_accuracy(net, data_iter):
    '''计算在指定数据集上模型的精度'''
    if isinstance(net, torch.nn.Module):
        net.eval() # 将模式设置为评估模式
    matric = Accumulator(2) # 正确预测数、预测总数
    with torch.no_grad():
        for X, y in data_iter:
            matric.add(accuracy(net(X), y), y.numel())
    return matric[0] / matric[1]
```

这里还需要定义一个实用程序类Accumulator，用于对多个变量进行累加，在上面的代码中，Accumulator中创建了两个变量，分别用于储存正确预测个数和预测总数。

```python
class Accumulator:
    def __init__(self, n):
        self.data = [0, 0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0, 0] * len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]
```

由于我们现在还没有进行优化，只是使用了正态分布进行参数初始化net模型，因此该模型的精度接近于随机猜测。这里有10个类型，猜测正确率应该在0.1左右.

```python
evaluate_accuracy(net, test_iter)
```

```
0.0798
```

有了训练集、损失函数、评价指标之后，我们就可以开始进行训练了。首先，我们定义一个函数来进行一轮训练。下面代码的updater是更新模型参数的常用函数，它可以接收批量大小作为参数，它可以是d2l.sgd函数，也可以是框架内置的优化函数。

```python
def train_epoch_ch3(net, train_iter, loss, updater): #@save
    """训练模型一个迭代周期"""
    # 将模型设置为训练模式
    if isinstance(net, torch.nn.Module):
        net.train()
            # 训练损失总和、训练准确度总和、样本数
    metric = Accumulator(3)
    for X, y in train_iter:
    # 计算梯度并更新参数
        y_hat = net(X)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):
        # 使用PyTorch内置的优化器和损失函数
            updater.zero_grad()
            l.mean().backward()
            updater.step()
        else:
        # 使用定制的优化器和损失函数
            l.sum().backward()
            updater(X.shape[0])
            metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    # 返回训练损失和训练精度
    return metric[0] / metric[2], metric[1] / metric[2]
```

在进行训练函数的实现之前，我们先来定义一个绘制图表的实用程序类Animator，可以用来动态绘制训练过程。

```python
class Animator:
    '''在动画中绘制数据'''
    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale='linear', yscale='linear',
                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1, figsize=(3.5, 2.5)):
        # 增量地画出多条线
        if legend is None:
            legend = []
        d2l.use_svg_display()
        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
        if nrows * ncols ==1:
            self.axes = [self.axes, ]
        # 实用lambda函数捕获参数
        self.config_axes = lambda: d2l.set_axes(
            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend
        )
        self.X, self.Y, self.fmts = None, None, fmts

    def add(self, x, y):
        # 向图表中添加多个数据点
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        if not hasattr(x, "__len__"):
            x = [x] * n
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)
        self.axes[0].cla()
        for x, y, fmt in zip(self.X, self.Y, self.fmts):
            self.axes[0].plot(x, y, fmt)
        self.config_axes()
        display.display(self.fig)
        display.clear_output(wait=True)        
```

接下来实现一个训练函数，在train_iter访问的训练数据集上训练一个模型net，可以进行多轮训练（由num_epochs指定）。在每轮训练结束之后，利用test_iter来访问测试机进行评估，并利用上面定义的Animator来可视化训练进度。

```python
def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save
    """训练模型"""
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train loss', 'train acc', 'test acc'])
    for epoch in range(num_epochs):
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc,))
    train_loss, train_acc = train_metrics
    assert train_loss < 0.5, train_loss
    assert train_acc <= 1 and train_acc > 0.7, train_acc
    assert test_acc <= 1 and test_acc > 0.7, test_acc
```

实用小批量随机梯度下降来优化损失函数，学习率定为0.1

```python
lr = 0.1 # 学习率

def updater(batch_size):
    return d2l.sgd([W, b], lr, batch_size)
```

```python
num_epochs = 10 #进行10轮训练
train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)
```

![](\figure\11.png)

模型训练好后就可以进行预测了，给定一系列的图像，并将他们的真实标签写在第一行，模型预测的标签输出在第二行。

```python
def predict_ch3(net, test_iter, n=8):
    '''预测标签'''
    for X, y in test_iter:
        break
    trues = d2l.get_fashion_mnist_labels(y)
    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))
    titles = [true + '\n' + pred for true, pred in zip(trues, preds)]
    # n是代表要展示多少个图片，可以任选（只要不超过测试集的数量即可）
    d2l.show_images(
        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]
    )

predict_ch3(net, test_iter, 20)
```

![](\figure\12.png)

#### softmax回归的简洁实现

与线性回归一样，softmax也有简洁实现，在这里我们依然实用Fashion-MNIST数据集，并保持批量大小为256。

```python
import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

模型参数初始化

```python
# pytorch不会隐式地调整输入的形状，因此在线性层之前定义一个展平层来调整网络输入的形状
net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) # 前面所说到的，一层神经网络，784维输入，10维输出

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights)
```

```
Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
  (1): Linear(in_features=784, out_features=10, bias=True)
)
```

由于损失函数的计算涉及到幂运算，从数值角度来看可能会造成某一部分过大或过小，因此我们可以先计算未经过softmax处理的未规范预测o，再计算o_j - max(o_k)并求和
$$
\log (\hat{y}_j) = o_j - \max (o_k) - \log (\sum_k \exp ( o_k - \max (o_k) )
$$

```python
loss = nn.CrossEntropyLoss(reduction='none')
trainer = torch.optim.SGD(net.parameters(), lr=0.1) # 使用少样本随机梯度下降法进行优化
```

注意：《动手学深度学习》中的之前写的train_epoch_ch3、evaluate_accuracy、train_ch3都是在CPU上运行的，但是使用了GPU版本pytorch就可能会出现一部分数据处于CPU中另一部分数据处于GPU中的情况，此时需要将所有的数据移动到GPU中运行，所以需要重新书写这三个函数

```python
import torch
from torch import nn

# 设置设备
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 训练一个epoch（内部使用GPU）
def train_epoch_ch3(net, train_iter, loss, updater):
    net.train()
    metric = Accumulator(3)  # 训练损失总和、训练准确度总和、样本数
    for X, y in train_iter:
        X, y = X.to(device), y.to(device)  # 关键一步：搬到 GPU
        y_hat = net(X)
        l = loss(y_hat, y)

        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.mean().backward()
            updater.step()
        else:
            l.sum().backward()
            updater(X.shape[0])

        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    return metric[0] / metric[2], metric[1] / metric[2]

# 评估准确率（也要搬到 GPU）
def evaluate_accuracy(net, data_iter):
    net.eval()
    metric = Accumulator(2)  # 正确预测数，总预测数
    with torch.no_grad():
        for X, y in data_iter:
            X, y = X.to(device), y.to(device)  # 关键一步
            metric.add(accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]

# 主训练函数
def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save
    net.to(device)  # 模型搬到 GPU
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train loss', 'train acc', 'test acc'])
    for epoch in range(num_epochs):
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc,))
    train_loss, train_acc = train_metrics
    assert train_loss < 0.5, train_loss
    assert train_acc <= 1 and train_acc > 0.7, train_acc
    assert test_acc <= 1 and test_acc > 0.7, test_acc
```

```python
num_epochs = 10
train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

![](\figure\13.png)

可以看出，简洁实现的softmax算法与的训练效果可以收敛到与之前相类似的精度，且代码简洁很多。











































