# 神经网络与深度学习3

在前面的实例中，我们使用了Fashion-MNIST图像数据集，这个数据集中的每个样本都由一个二维像素网格组成，每个像素可能是一个数值（黑白图像——灰度值）或多个数值（彩色图像——RGB）。但我们的网络结构还不够复杂，处理方式还不够有效，仅将图像展平成一个一位的向量而忽略了每个元素的空间信息。

因此这里我们开始进入卷积神经网络（CNN）——一个专门为了处理图像数据而设计的强大的神经网络，从这里开始我们进入了“深度学习”——深度神经网络。

## 为什么要“深度学习”

以往全连接网络存在一些缺陷：节点过多，计算速度慢，难收敛，可能陷入局部最优也容易产生过拟合。
例如：输入的图像样本为1000×1000的图像，隐含层中有1M个节点，则仅从输入到隐含层中就需要处理10^12数量级的参数，更不用说每个训练集、验证集中有多少样本，且这还只是对于黑白图像而言。

怎么才能解决计算速度慢的问题呢？
减少权值连接，即不适用全连接网络，每个节点只连接到上一层的少数神经元，即局部连接网络。

怎么样才能解决权值过多容易产生过拟合的问题呢？
将信息分层处理，即增加神经网络的“深度”而不是“宽度”。每一层在上一层提取特征的基础上再进行处理，得到更高级别的特征。

深度学习平台简介

|     库名      |   发布者    |              支持语言              |             支持系统              |
| :-----------: | :---------: | :--------------------------------: | :-------------------------------: |
|  TensorFlow   |   Google    |         Python/C++/Java/Go         |     Linux/Mac OS/Android/iOS      |
|     Caffe     | UC Berkeley |         Python/C++/MATLAB          |       Linux/Mac OS/Windows        |
|      JAX      |   Google    |               Python               |           Linux/Windows           |
|     MXNet     | Amazon/DMLC | Python/C++/MATLAB/Julia/Go/R/Scala | Linux/Mac OS/ Windows/Android/iOS |
| Torch/PyTorch |  Facebook   |            C/Python/...            | Linux/Mac OS/ Windows/Android/iOS |
| PaddlePaddle  |    百度     |               Python               |           Linux/Windows           |
|  MMdetection  | 商汤/港中文 |               Python               |           Linux/Windows           |

|     库名      | 学习材料丰富程度 | CNN建模能力 | RNN建模能力 | 易用程度 | 运行速度 | 多GPU支持程度 |
| :-----------: | :--------------: | :---------: | :---------: | :------: | :------: | :-----------: |
|  TensorFlow   |       ⭐⭐⭐        |     ⭐⭐⭐     |     ⭐⭐⭐     |   ⭐⭐※    |   ⭐⭐※    |      ⭐⭐⭐      |
|     Caffe     |        ⭐⭐        |     ⭐⭐      |      ⭐      |    ⭐     |   ⭐⭐⭐    |       ⭐       |
|      JAX      |        ⭐⭐        |     ⭐⭐      |     ⭐⭐      |   ⭐⭐⭐    |   ⭐⭐⭐    |      ⭐⭐⭐      |
|     MXNet     |       ⭐⭐※        |     ⭐⭐      |     ⭐⭐      |   ⭐⭐※    |   ⭐⭐※    |      ⭐⭐⭐      |
| Torch/PyTorch |       ⭐⭐⭐        |     ⭐⭐⭐     |     ⭐⭐⭐     |   ⭐⭐⭐⭐   |   ⭐⭐※    |      ⭐⭐※      |
| PaddlePaddle  |        ⭐⭐        |     ⭐⭐      |     ⭐⭐      |   ⭐⭐⭐⭐   |    ⭐⭐    |       ⭐       |
|  MMdetection  |        ⭐⭐        |     ⭐⭐      |      ⭐      |   ⭐⭐⭐⭐   |   ⭐⭐※    |       ⭐       |

## 卷积神经网络基础

卷积神经网络常用来对图像进行识别，在图像识别中我们可以进行一个合理的假设：对于一个确定的物体，无论其位于什么位置，我们都可以使用某种方式来找到这个物体，即物体的“空间不变性”，卷积神经网络症是将这一空间不变性的概念系统化，从而使用较少的参数来学习有用的表示。

卷积神经网络要满足两个特性：
平移不变性：不管检测对象出现在图像中的哪个位置，神经网络的前面几层都应该对相同的图像区域有相似的反应，即”平移不变性“。
局部性：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系。

### 卷积神经网络的数学表示

整个卷积神经网络可以分为两部分，与输入层连接的是部分连接层（卷积层与池化层），与输出层连接的部分是一个全连接层。且输入为一个二维图像，即一个二维矩阵（在PyTorch中称为张量），因此在前半部分卷积神经网络——部分连接层中的隐藏层输入以及输出都应该是二维矩阵，偏置也应该是二维矩阵，但权重呢？

我们需要深入思考一下这部分的权重（卷积核）需要完成什么样的功能。

因为要关注局部性，所以需要一个卷积核（把周围的特征都聚集在一起）；且需要满足平移不变性，因此对于任何位置的卷积核都要一模一样。

首先，对于一个输入的图片，可能只有1个通道（黑白图像只有灰度），也可能有3个通道（RGB），因此卷积核需要包含输入图片的通道数；

其次就是需要有多少个卷积核，以输入为5×5，卷积核为3×3作为例子：

![](/figure/22.png)

图中的输入矩阵和卷积核分别为：



![](/figure/matrix/6.png)




$$
\begin{bmatrix} 
1 & 1 & 1 & 0 & 0 \\
0 & 1 & 1 & 1 & 0 \\
0 & 0 & 1 & 1 & 1 \\
0 & 0 & 1 & 1 & 0 \\
0 & 1 & 1 & 0 & 0 \\
\end{bmatrix}

和

\begin{bmatrix} 
1 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 1 \\
\end{bmatrix}
$$
在输入矩阵的左上角3×3的部分，使用卷积核与这部分对应位置的元素相乘再相加，就获得了卷积后特征的第一个元素；同理对于输入矩阵正上方3×3的部分也使用卷积核对应位置元素相乘再相加，这就获得了卷积后特征的第二个元素；这样需要进行9次运算（以步长为1来计算）。

因此，部分连接层的权重应该是一个四维的张量，其第一维是有多少个卷积核，第二维是输入图像有多少个通道，第三维和第四维是卷积核的高度与宽度。以上面这个例子来说，如果输入是黑白图片，那么部分连接层的权重形状为：9×1×3×3；如果输入是彩色图片，那么部分连接层的权重形状为：9×3×3×3。

而卷积后的特征形状要怎么计算呢？从上面的图片可以看到，卷积后的特征矩阵从原本的5×5变成了3×3，事实上，卷积后特征矩阵的形状与“卷积核形状、步长、填充”相关（步长和填充后面进行解释）。计算公式为：
$$
H_{out} = [ \frac{H_{in}+2P_{h}-K_{h}}{S_{h}} ] + 1,
W_{out} = [ \frac{W_{in}+2P_{w}-K_{w}}{S_{w}} ] + 1
$$
上面的式子中H/h和W/w代表高度和宽度，P、K和S代表填充、卷积核和步长，“ [ ] ”代表向下取整。使用图片中的例子来进行计算：在原本的图像中没有进行填充，因此P_h、P_w都为0；K_h、K_w都为3；高度和宽度步长都为1，即S_h和S_w都为1；H_out和W_out都可计算得3。

【注】如果输入的通道数是1，则卷积核运算后的输出通道数也为1；如果输入的通道数是3，则卷积核运算后的输出通道数也为3；

### 自己的一些理解

【注】由于部分连接层中的权重是一个四维的张量，对于笔者而言，想要理解一个三维的张量还好说，针对四维的张量就只能抽象一点了。以下只是自己的一些理解，并不完全正确（但方便对后面的公式进行理解）。

还是从前面的例子入手：

1. 输入为黑白图片（单通道），卷积核为3×3，步长为1，无填充，因此输出的形状为3×3；权重的形状为9×1×3×3。对于所有输出的位置，都需要进行一次卷积核的运算，而每次卷积核都只对自己覆盖住的范围来进行运算。我们不妨把卷积核扩展一下，把3×3的卷积核扩展成5×5，原本3×3的卷积核在扩展后5×5的张量中的位置就是卷积核覆盖输入的位置，其余位置均为0。

   第一个卷积核扩展的张量（权重的第一个维度可以联想为卷积核的序号），如下图所示，卷积核扩展后的白色部分都为0，第一个张量中所有的元素的位置用四维坐标表示（1, 1, i, j），计算出来的结果放在输出的第1个元素。

![](/figure/23.png)

​	第二个由卷积核扩展得到的张量如下图所示，第二个张量中所有的元素的位置用四维坐标表示（2, 1, i, j），黄色部分是卷积核与第一个卷积核——第一个张量中的黄色部分一模一样（平移不变性），计算出来的结果放在输出的第2个元素。

![](/figure/24.png)

​	以此类推，这样的张量共有9个。

2. 输入为彩色图片（3通道），所以部分连接层中的权重形状为9×3×3×3。与1中相类似，只不过卷积核不再是一个二维的了，而是一个三维的，同样这样的卷积核有9个。

​	第一个卷积核扩展所得的张量如下图所示，红、绿、蓝部分是卷积核，在张量中的位置与其所覆盖输入的位置一样，卷积核的计算：卷积核的第一个通道（蓝色）与输入的第一个通道中对应元素相乘再相加；第二个通道（绿色）与第三个通道（红色）再进行与第一个通道的同样步骤，并将各通道的计算结果放入输出张量各通道的第一个位置。这个张量第一通道（蓝色部分的通道）各元素的坐标为（1, 1, i, j）；第二通道（绿色部分的通道）各元素的坐标为（1, 2, i, j）；第三通道（红色部分的通道）各元素的坐标为（1, 3, i, j）。

![](/figure/25.png)

​	第二个卷积核扩展所得的张量如下图所示，卷积核的计算步骤与上述步骤一样，计算结果放在输出张量中的第二个位置。这个张量第一通道（蓝色部分的通道）各元素的坐标为（2, 1, i, j）；第二通道（绿色部分的通道）各元素的坐标为（2, 2, i, j）；第三通道（红色部分的通道）各元素的坐标为（2, 3, i, j）。并且，第二个张量中的蓝色部分与第一个张量中的蓝色部分一模一样，同理绿色与红色（各通道的平移不变性）。

![](/figure/26.png)

### 基本概念

1. 填充（Padding）

在前面的卷积核计算中我们知道，经过卷积核运算，输出的形状比输入的形状会稍微“小一些”，有的时候我们并不想让他“变小”，因此我们需要在输入中进行填充，让输入先“变大”，这样就可以让输出和输入的大小一样，常见的对输入进行填充的方式有：把边缘填充为0或复制边界像素。

![](/figure/27.png)

2. 步长（Stride）

执行一次卷积核运算后，平移多少格再次进行卷积核运算：

![](/figure/28.png)

3. 池化（Pooling）

针对局部特征进行统计，计算出一个特征值来代表这个部分的特征（例如均值或最大值）

![](/figure/29.png)

在部分连接层中，可以使用多个卷积层和池化层，充分提取图片特征。在部分连接层的最后一层输出后，对所有的张量进行展平操作，再连入全连接层中。

如下面这个图是一个LeNet-5网络

![](/figure/30.png)

部分连接层和全连接层，构成了完整的卷积神经网络。下面这个网站是一个LeNet-5网络，可以进行手写数字，然后让LeNet-5网络来识别手写的数字为多少，并对每一层网络都进行了可视化，可以更好地理解卷积神经网络的结构。

[3D Visualization of a Convolutional Neural Network](https://adamharley.com/nn_vis/cnn/3d.html)

### 卷积神经网络的数学表示

卷积神经网络前向传播的定义为：
$$
z^{[l]}(x,y) = \sum_{u=0}^{p} \sum_{v=0}^{q}  a^{[l-1]}(x+u,y+v)w^{[l],k}(u,v)
$$

$$
a^{[l]}(x,y) = f(z^{[l]}(x,y))
$$

若第l层是卷积+池化层，则：
$$
a^{[l]}(x,y) = \text{downsample}(\sum_{u=0}^{p} \sum_{v=0}^{q}  a^{[l-1]}(x+u,y+v)w_s(u,v))
$$
对于卷积神经网络的BP算法：
$$
a^{[l]}(x_1,y_1) = f(\sum_{u=0}^{p} \sum_{v=0}^{q}  a^{[l-1]}(x_1+u,y_1+v)w^{[l],k}(u,v))
$$

$$
...
$$

$$
a^{[l+1]}(x_i,y_i)=f(\sum_{u=0}^{p} \sum_{v=0}^{q}  a^{[l]}(x_i+u,y_j+v)w^{[l],k}(u,v))
$$

$$
\frac{\partial a^{[l+1](x_i,y_i)}}{\partial w^{[l],k}} =
\sum_{u=0}^{p} \sum_{v=0}^{q} 
\frac{\partial a^{[l+1](x_i,y_i)}}{\partial a^{[l](x_i+u,y_i+v)}}
\frac{\partial a^{[l](x_i+u,y_i+v)}}{\partial w^{[l],k}}
$$

## LeNet-5网络

### LeNet-5网络结构

LeNet-5网络的结构前面有提到过，如下图所示。

![](/figure/30.png)

输入：一个单通道32×32维的张量；

1. 第一个卷积层：将输入层单通道32×32维张量进行卷积运算，使用六个不同的5×5的卷积核、单步长、不进行填充来进行运算，得到六通道28×28维的输出；

2. 第一个池化层：将第一个卷积层的输出中2×2的区域进行池化，每个2×2的区域都获得一个池化后的特征值（最大或平均），得到六通道14×14的输出；

3. 第二个卷积层：第二个卷积层接收到第一个池化层中的六通道14×14的输入后，又输出了一个十六通道的10×10的输出。这个过程稍微有点复杂，需要结合下面这个表格来看。

|      |  0   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |  9   |  10  |  11  |  12  |  13  |  14  |  15  |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  0   |  √   |      |      |      |  √   |  √   |  √   |      |      |  √   |  √   |  √   |  √   |      |  √   |  √   |
|  1   |  √   |  √   |      |      |      |  √   |  √   |  √   |      |      |  √   |  √   |  √   |  √   |      |  √   |
|  2   |  √   |  √   |  √   |      |      |      |  √   |  √   |  √   |      |      |  √   |      |  √   |  √   |  √   |
|  3   |      |  √   |  √   |  √   |      |      |  √   |  √   |  √   |  √   |      |      |  √   |      |  √   |  √   |
|  4   |      |      |  √   |  √   |  √   |      |      |  √   |  √   |  √   |  √   |      |  √   |  √   |      |  √   |
|  5   |      |      |      |  √   |  √   |  √   |      |      |  √   |  √   |  √   |  √   |      |  √   |  √   |  √   |

​	行代表输入，列代表输出。需要注意的是，对于输入的每个通道，都有其专属的卷积核，例如第0行，有一个卷积核K_0，第1行有一个卷积核K_1。
​	不同的输出需要使用相应输入通道的组合。例如第0列，使用了0，1，2三个通道的输入，将每个输入通道使用各自对应的5×5的卷积核进行运算后再相加，即：
​	通道0与K_0进行运算得到F_0，通道1与K_1进行运算得到F_1，通道2与K_2进行运算得到F_2；该卷积层的输出第0通道如下，其中b为偏置项（不同输出通道有不同的偏置）。
$$
O_0 = F_0 + F_1 + F_2 + b_0
$$
​	这种计算方式叫做“**跨通道卷积求和**”

​	如此就可以得到十六通道10×10的输出。

​	也可以在之前所提到的可视化网站中进行观察：[3D Visualization of a Convolutional Neural Network](https://adamharley.com/nn_vis/cnn/3d.html)

![](/figure/32.png)

4. 第二个池化层：得到第二个卷积层十六通道的输入后，再分别对每个通道进行2×2范围的池化，就可以得到十六通道5×5的输出了。

5. 全连接层：将第二个池化层的输出展平作为输入，连入到全连接层中，最终计算得到输出。

这就是一个完整的LeNet-5网络结构。

### LeNet-5网络的代码实现

在使用pytorch实现LeNet-5网络时，torch.nn中有一个卷积的方法可以直接调用:

nn.Conv2d(1, 6, kernel_size=5, padding=2)

Conv2d(1, 6, kernel_size=5, padding=2)中，第一个参数是输入通道数目，第二个参数是输出通道参数，然后是卷积核、填充。

```python
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
                    nn.Conv2d(1, 6, kernel_size=5, padding=2), # 卷积层，输入通道数1，输出通道数6，卷积核大小5*5,填充为2
                    nn.Sigmoid(), # 使用激活函数Sigmoid对卷积层的输出进行非线性变换
                    nn.AvgPool2d(kernel_size=2, stride=2), # 平均池化层，池化窗口大小2*2，步幅为2
                    nn.Conv2d(6, 16, kernel_size=5), # 卷积层，输入通道数6，输出通道数16，卷积核大小5*5,不进行填充
                    nn.AvgPool2d(kernel_size=2, stride=2), # 平均池化层，池化窗口大小2*2，步幅为2
                    nn.Flatten(), # 展平层，将多维输入展平为一维
                    nn.Linear(16 * 5 * 5, 120), # 全连接层，输入特征数16*5*5，输出特征数120
                    nn.Sigmoid(), # 使用激活函数Sigmoid对全连接层的输出进行非线性变换
                    nn.Linear(120, 84), # 全连接层，输入特征数120，输出特征数84
                    nn.Sigmoid(), # 原本这部分的激活函数应该是高斯激活函数，但在这里还是使用Sigmoid进行激活
                    nn.Linear(84, 10) # 全连接层，输入特征数84，输出特征数10（分类数）
                    )
```

```python
# 进行前向计算
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32) # 随机生成一个输入数据，形状为(1, 1, 28, 28)
for layer in net: # 遍历网络中的每一层
    X = layer(X) # 将输入数据传入每一层进行前向传播
    print(layer.__class__.__name__, 'output shape:\t', X.shape) # 打印每一层的输出形状
```

输出：

```tex
Conv2d output shape:	 torch.Size([1, 6, 28, 28])
Sigmoid output shape:	 torch.Size([1, 6, 28, 28])
AvgPool2d output shape:	 torch.Size([1, 6, 14, 14])
Conv2d output shape:	 torch.Size([1, 16, 10, 10])
AvgPool2d output shape:	 torch.Size([1, 16, 5, 5])
Flatten output shape:	 torch.Size([1, 400])
Linear output shape:	 torch.Size([1, 120])
Sigmoid output shape:	 torch.Size([1, 120])
Linear output shape:	 torch.Size([1, 84])
Sigmoid output shape:	 torch.Size([1, 84])
Linear output shape:	 torch.Size([1, 10])
```

在对网络进行训练之前，我们再定义一个训练器。在Train.py文件中添加如下代码

```python
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device): #@save
    """第六章的模型训练器"""
    print(">>> train_ch6 函数开始执行", flush=True)
    def init_weights(m):
        if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:
            torch.nn.init.xavier_uniform_(m.weight)
    net.apply(init_weights)
    print("trainning on", device)
    net.to(device)
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    loss = torch.nn.CrossEntropyLoss()
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs],
                        legend=['train loss', 'train acc', 'test acc'])
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        metric = Accumulator(3) # 训练损失总和、训练准确度总和、样本数
        net.train()
        for i, (X, y) in enumerate(train_iter):
            timer.start()
            optimizer.zero_grad()
            X, y = X.to(device), y.to(device)
            y_hat = net(X)
            l = loss(y_hat, y)
            l.backward()
            optimizer.step()
            with torch.no_grad():
                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])
            timer.stop()
            train_l = metric[0] / metric[2]
            train_acc = metric[1] / metric[2]
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches, (train_l, train_acc, None))
        test_acc = evaluate_accuracy(net, test_iter, device)
        animator.add(epoch + 1, (None, None, test_acc))
    print(f'train loss {train_l:.3f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on {str(device)}')

```

然后对模型进行训练：

```python
from Train import train_ch6

lr, num_epochs = 0.9, 10 # 学习率和训练轮数
train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) # 训练模型
```

得到的输出为：

```tex
train loss 0.347, train acc 0.872, test acc 0.852
37512.4 examples/sec on cuda:0
```

![](/figure/33.png)















